{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TprtqAhLn9w8"
   },
   "source": [
    "# CODING TASK #1: IMPORT DATASET AND LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from Pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from Pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from Pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->Pandas) (1.14.0)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVrKXCk4njhr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1soONkDu67P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the csv files using pandas \n",
    "bike_df = pd.read_csv('bike_sharing_daily.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>12/27/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>12/28/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>12/29/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>12/30/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>12/31/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1    1/1/2011       1   0     1        0        6           0   \n",
       "1          2    1/2/2011       1   0     1        0        0           0   \n",
       "2          3    1/3/2011       1   0     1        0        1           1   \n",
       "3          4    1/4/2011       1   0     1        0        2           1   \n",
       "4          5    1/5/2011       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  12/27/2012       1   1    12        0        4           1   \n",
       "727      728  12/28/2012       1   1    12        0        5           1   \n",
       "728      729  12/29/2012       1   1    12        0        6           0   \n",
       "729      730  12/30/2012       1   1    12        0        0           0   \n",
       "730      731  12/31/2012       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp       hum  windspeed  casual  registered   cnt  \n",
       "0             2  0.344167  0.805833   0.160446     331         654   985  \n",
       "1             2  0.363478  0.696087   0.248539     131         670   801  \n",
       "2             1  0.196364  0.437273   0.248309     120        1229  1349  \n",
       "3             1  0.200000  0.590435   0.160296     108        1454  1562  \n",
       "4             1  0.226957  0.436957   0.186900      82        1518  1600  \n",
       "..          ...       ...       ...        ...     ...         ...   ...  \n",
       "726           2  0.254167  0.652917   0.350133     247        1867  2114  \n",
       "727           2  0.253333  0.590000   0.155471     644        2451  3095  \n",
       "728           2  0.253333  0.752917   0.124383     159        1182  1341  \n",
       "729           1  0.255833  0.483333   0.350754     364        1432  1796  \n",
       "730           2  0.215833  0.577500   0.154846     439        2290  2729  \n",
       "\n",
       "[731 rows x 15 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the dataframe\n",
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1/6/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>0.518261</td>\n",
       "      <td>0.089565</td>\n",
       "      <td>88</td>\n",
       "      <td>1518</td>\n",
       "      <td>1606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1/7/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.498696</td>\n",
       "      <td>0.168726</td>\n",
       "      <td>148</td>\n",
       "      <td>1362</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1/8/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.266804</td>\n",
       "      <td>68</td>\n",
       "      <td>891</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1/9/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.434167</td>\n",
       "      <td>0.361950</td>\n",
       "      <td>54</td>\n",
       "      <td>768</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1/10/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150833</td>\n",
       "      <td>0.482917</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>41</td>\n",
       "      <td>1280</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1   1/1/2011       1   0     1        0        6           0   \n",
       "1        2   1/2/2011       1   0     1        0        0           0   \n",
       "2        3   1/3/2011       1   0     1        0        1           1   \n",
       "3        4   1/4/2011       1   0     1        0        2           1   \n",
       "4        5   1/5/2011       1   0     1        0        3           1   \n",
       "5        6   1/6/2011       1   0     1        0        4           1   \n",
       "6        7   1/7/2011       1   0     1        0        5           1   \n",
       "7        8   1/8/2011       1   0     1        0        6           0   \n",
       "8        9   1/9/2011       1   0     1        0        0           0   \n",
       "9       10  1/10/2011       1   0     1        0        1           1   \n",
       "\n",
       "   weathersit      temp       hum  windspeed  casual  registered   cnt  \n",
       "0           2  0.344167  0.805833   0.160446     331         654   985  \n",
       "1           2  0.363478  0.696087   0.248539     131         670   801  \n",
       "2           1  0.196364  0.437273   0.248309     120        1229  1349  \n",
       "3           1  0.200000  0.590435   0.160296     108        1454  1562  \n",
       "4           1  0.226957  0.436957   0.186900      82        1518  1600  \n",
       "5           1  0.204348  0.518261   0.089565      88        1518  1606  \n",
       "6           2  0.196522  0.498696   0.168726     148        1362  1510  \n",
       "7           2  0.165000  0.535833   0.266804      68         891   959  \n",
       "8           1  0.138333  0.434167   0.361950      54         768   822  \n",
       "9           1  0.150833  0.482917   0.223267      41        1280  1321  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>722</td>\n",
       "      <td>12/22/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265833</td>\n",
       "      <td>0.441250</td>\n",
       "      <td>0.407346</td>\n",
       "      <td>205</td>\n",
       "      <td>1544</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>723</td>\n",
       "      <td>12/23/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.515417</td>\n",
       "      <td>0.133083</td>\n",
       "      <td>408</td>\n",
       "      <td>1379</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>724</td>\n",
       "      <td>12/24/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.231304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.077230</td>\n",
       "      <td>174</td>\n",
       "      <td>746</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>725</td>\n",
       "      <td>12/25/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291304</td>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.168726</td>\n",
       "      <td>440</td>\n",
       "      <td>573</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>726</td>\n",
       "      <td>12/26/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.316546</td>\n",
       "      <td>9</td>\n",
       "      <td>432</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>12/27/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>12/28/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>12/29/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>12/30/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>12/31/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "721      722  12/22/2012       1   1    12        0        6           0   \n",
       "722      723  12/23/2012       1   1    12        0        0           0   \n",
       "723      724  12/24/2012       1   1    12        0        1           1   \n",
       "724      725  12/25/2012       1   1    12        1        2           0   \n",
       "725      726  12/26/2012       1   1    12        0        3           1   \n",
       "726      727  12/27/2012       1   1    12        0        4           1   \n",
       "727      728  12/28/2012       1   1    12        0        5           1   \n",
       "728      729  12/29/2012       1   1    12        0        6           0   \n",
       "729      730  12/30/2012       1   1    12        0        0           0   \n",
       "730      731  12/31/2012       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp       hum  windspeed  casual  registered   cnt  \n",
       "721           1  0.265833  0.441250   0.407346     205        1544  1749  \n",
       "722           1  0.245833  0.515417   0.133083     408        1379  1787  \n",
       "723           2  0.231304  0.791304   0.077230     174         746   920  \n",
       "724           2  0.291304  0.734783   0.168726     440         573  1013  \n",
       "725           3  0.243333  0.823333   0.316546       9         432   441  \n",
       "726           2  0.254167  0.652917   0.350133     247        1867  2114  \n",
       "727           2  0.253333  0.590000   0.155471     644        2451  3095  \n",
       "728           2  0.253333  0.752917   0.124383     159        1182  1341  \n",
       "729           1  0.255833  0.483333   0.350754     364        1432  1796  \n",
       "730           2  0.215833  0.577500   0.154846     439        2290  2729  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     731 non-null    int64  \n",
      " 1   dteday      731 non-null    object \n",
      " 2   season      731 non-null    int64  \n",
      " 3   yr          731 non-null    int64  \n",
      " 4   mnth        731 non-null    int64  \n",
      " 5   holiday     731 non-null    int64  \n",
      " 6   weekday     731 non-null    int64  \n",
      " 7   workingday  731 non-null    int64  \n",
      " 8   weathersit  731 non-null    int64  \n",
      " 9   temp        731 non-null    float64\n",
      " 10  hum         731 non-null    float64\n",
      " 11  windspeed   731 non-null    float64\n",
      " 12  casual      731 non-null    int64  \n",
      " 13  registered  731 non-null    int64  \n",
      " 14  cnt         731 non-null    int64  \n",
      "dtypes: float64(3), int64(11), object(1)\n",
      "memory usage: 85.8+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 [OPTIONAL]:**\n",
    "- **Compare the Average casual, registered and total bike sharing demand** \n",
    "- **Does the average value of casual and registered sum up to the overall average total demand?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>2.496580</td>\n",
       "      <td>0.500684</td>\n",
       "      <td>6.519836</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>2.997264</td>\n",
       "      <td>0.683995</td>\n",
       "      <td>1.395349</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>848.176471</td>\n",
       "      <td>3656.172367</td>\n",
       "      <td>4504.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>211.165812</td>\n",
       "      <td>1.110807</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>3.451913</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>2.004787</td>\n",
       "      <td>0.465233</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>686.622488</td>\n",
       "      <td>1560.256377</td>\n",
       "      <td>1937.211452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>183.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "      <td>315.500000</td>\n",
       "      <td>2497.000000</td>\n",
       "      <td>3152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>366.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>3662.000000</td>\n",
       "      <td>4548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>548.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>4776.500000</td>\n",
       "      <td>5956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>3410.000000</td>\n",
       "      <td>6946.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          instant      season          yr        mnth     holiday     weekday  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean   366.000000    2.496580    0.500684    6.519836    0.028728    2.997264   \n",
       "std    211.165812    1.110807    0.500342    3.451913    0.167155    2.004787   \n",
       "min      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "25%    183.500000    2.000000    0.000000    4.000000    0.000000    1.000000   \n",
       "50%    366.000000    3.000000    1.000000    7.000000    0.000000    3.000000   \n",
       "75%    548.500000    3.000000    1.000000   10.000000    0.000000    5.000000   \n",
       "max    731.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n",
       "\n",
       "       workingday  weathersit        temp         hum   windspeed  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean     0.683995    1.395349    0.495385    0.627894    0.190486   \n",
       "std      0.465233    0.544894    0.183051    0.142429    0.077498   \n",
       "min      0.000000    1.000000    0.059130    0.000000    0.022392   \n",
       "25%      0.000000    1.000000    0.337083    0.520000    0.134950   \n",
       "50%      1.000000    1.000000    0.498333    0.626667    0.180975   \n",
       "75%      1.000000    2.000000    0.655417    0.730209    0.233214   \n",
       "max      1.000000    3.000000    0.861667    0.972500    0.507463   \n",
       "\n",
       "            casual   registered          cnt  \n",
       "count   731.000000   731.000000   731.000000  \n",
       "mean    848.176471  3656.172367  4504.348837  \n",
       "std     686.622488  1560.256377  1937.211452  \n",
       "min       2.000000    20.000000    22.000000  \n",
       "25%     315.500000  2497.000000  3152.000000  \n",
       "50%     713.000000  3662.000000  4548.000000  \n",
       "75%    1096.000000  4776.500000  5956.000000  \n",
       "max    3410.000000  6946.000000  8714.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #2: PERFORM DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bike_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a24fd6250>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(bike_df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>12/27/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>12/28/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>12/29/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>12/30/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>12/31/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1    1/1/2011       1   0     1        0        6           0   \n",
       "1          2    1/2/2011       1   0     1        0        0           0   \n",
       "2          3    1/3/2011       1   0     1        0        1           1   \n",
       "3          4    1/4/2011       1   0     1        0        2           1   \n",
       "4          5    1/5/2011       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  12/27/2012       1   1    12        0        4           1   \n",
       "727      728  12/28/2012       1   1    12        0        5           1   \n",
       "728      729  12/29/2012       1   1    12        0        6           0   \n",
       "729      730  12/30/2012       1   1    12        0        0           0   \n",
       "730      731  12/31/2012       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp       hum  windspeed  casual  registered   cnt  \n",
       "0             2  0.344167  0.805833   0.160446     331         654   985  \n",
       "1             2  0.363478  0.696087   0.248539     131         670   801  \n",
       "2             1  0.196364  0.437273   0.248309     120        1229  1349  \n",
       "3             1  0.200000  0.590435   0.160296     108        1454  1562  \n",
       "4             1  0.226957  0.436957   0.186900      82        1518  1600  \n",
       "..          ...       ...       ...        ...     ...         ...   ...  \n",
       "726           2  0.254167  0.652917   0.350133     247        1867  2114  \n",
       "727           2  0.253333  0.590000   0.155471     644        2451  3095  \n",
       "728           2  0.253333  0.752917   0.124383     159        1182  1341  \n",
       "729           1  0.255833  0.483333   0.350754     364        1432  1796  \n",
       "730           2  0.215833  0.577500   0.154846     439        2290  2729  \n",
       "\n",
       "[731 rows x 15 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop(labels = ['instant'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>12/27/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>12/28/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>12/29/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>12/30/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>12/31/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dteday  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0      1/1/2011       1   0     1        0        6           0           2   \n",
       "1      1/2/2011       1   0     1        0        0           0           2   \n",
       "2      1/3/2011       1   0     1        0        1           1           1   \n",
       "3      1/4/2011       1   0     1        0        2           1           1   \n",
       "4      1/5/2011       1   0     1        0        3           1           1   \n",
       "..          ...     ...  ..   ...      ...      ...         ...         ...   \n",
       "726  12/27/2012       1   1    12        0        4           1           2   \n",
       "727  12/28/2012       1   1    12        0        5           1           2   \n",
       "728  12/29/2012       1   1    12        0        6           0           2   \n",
       "729  12/30/2012       1   1    12        0        0           0           1   \n",
       "730  12/31/2012       1   1    12        0        1           1           2   \n",
       "\n",
       "         temp       hum  windspeed  casual  registered   cnt  \n",
       "0    0.344167  0.805833   0.160446     331         654   985  \n",
       "1    0.363478  0.696087   0.248539     131         670   801  \n",
       "2    0.196364  0.437273   0.248309     120        1229  1349  \n",
       "3    0.200000  0.590435   0.160296     108        1454  1562  \n",
       "4    0.226957  0.436957   0.186900      82        1518  1600  \n",
       "..        ...       ...        ...     ...         ...   ...  \n",
       "726  0.254167  0.652917   0.350133     247        1867  2114  \n",
       "727  0.253333  0.590000   0.155471     644        2451  3095  \n",
       "728  0.253333  0.752917   0.124383     159        1182  1341  \n",
       "729  0.255833  0.483333   0.350754     364        1432  1796  \n",
       "730  0.215833  0.577500   0.154846     439        2290  2729  \n",
       "\n",
       "[731 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['casual' 'registered'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a5e1a544a7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbike_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbike_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'casual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'registered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbike_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdteday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['casual' 'registered'] not found in axis\""
     ]
    }
   ],
   "source": [
    "bike_df = bike_df.drop(labels = ['casual', 'registered'], axis = 1)\n",
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dteday\n",
       "2011-01-01      1/1/2011\n",
       "2011-01-02      1/2/2011\n",
       "2011-01-03      1/3/2011\n",
       "2011-01-04      1/4/2011\n",
       "2011-01-05      1/5/2011\n",
       "                 ...    \n",
       "2012-12-27    12/27/2012\n",
       "2012-12-28    12/28/2012\n",
       "2012-12-29    12/29/2012\n",
       "2012-12-30    12/30/2012\n",
       "2012-12-31    12/31/2012\n",
       "Name: dteday, Length: 731, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df['bteday'] = pd.to_datetime(bike_df['dteday'], format = '%m/%d/%Y')\n",
    "bike_df.dteday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>bteday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dteday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>1/2/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>2011-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>1/3/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>2011-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>1/4/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>2011-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>1/5/2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>2011-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-27</th>\n",
       "      <td>12/27/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "      <td>2012-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-28</th>\n",
       "      <td>12/28/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "      <td>2012-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-29</th>\n",
       "      <td>12/29/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "      <td>2012-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>12/30/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>12/31/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "      <td>2012-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "dteday                                                                   \n",
       "2011-01-01    1/1/2011       1   0     1        0        6           0   \n",
       "2011-01-02    1/2/2011       1   0     1        0        0           0   \n",
       "2011-01-03    1/3/2011       1   0     1        0        1           1   \n",
       "2011-01-04    1/4/2011       1   0     1        0        2           1   \n",
       "2011-01-05    1/5/2011       1   0     1        0        3           1   \n",
       "...                ...     ...  ..   ...      ...      ...         ...   \n",
       "2012-12-27  12/27/2012       1   1    12        0        4           1   \n",
       "2012-12-28  12/28/2012       1   1    12        0        5           1   \n",
       "2012-12-29  12/29/2012       1   1    12        0        6           0   \n",
       "2012-12-30  12/30/2012       1   1    12        0        0           0   \n",
       "2012-12-31  12/31/2012       1   1    12        0        1           1   \n",
       "\n",
       "            weathersit      temp       hum  windspeed   cnt     bteday  \n",
       "dteday                                                                  \n",
       "2011-01-01           2  0.344167  0.805833   0.160446   985 2011-01-01  \n",
       "2011-01-02           2  0.363478  0.696087   0.248539   801 2011-01-02  \n",
       "2011-01-03           1  0.196364  0.437273   0.248309  1349 2011-01-03  \n",
       "2011-01-04           1  0.200000  0.590435   0.160296  1562 2011-01-04  \n",
       "2011-01-05           1  0.226957  0.436957   0.186900  1600 2011-01-05  \n",
       "...                ...       ...       ...        ...   ...        ...  \n",
       "2012-12-27           2  0.254167  0.652917   0.350133  2114 2012-12-27  \n",
       "2012-12-28           2  0.253333  0.590000   0.155471  3095 2012-12-28  \n",
       "2012-12-29           2  0.253333  0.752917   0.124383  1341 2012-12-29  \n",
       "2012-12-30           1  0.255833  0.483333   0.350754  1796 2012-12-30  \n",
       "2012-12-31           2  0.215833  0.577500   0.154846  2729 2012-12-31  \n",
       "\n",
       "[731 rows x 13 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.index = pd.DatetimeIndex(bike_df['dteday'])\n",
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>bteday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dteday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>2011-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>2011-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>2011-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>2011-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "      <td>2012-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "      <td>2012-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "      <td>2012-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "      <td>2012-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "      <td>2012-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "dteday                                                                   \n",
       "2011-01-01       1   0     1        0        6           0           2   \n",
       "2011-01-02       1   0     1        0        0           0           2   \n",
       "2011-01-03       1   0     1        0        1           1           1   \n",
       "2011-01-04       1   0     1        0        2           1           1   \n",
       "2011-01-05       1   0     1        0        3           1           1   \n",
       "...            ...  ..   ...      ...      ...         ...         ...   \n",
       "2012-12-27       1   1    12        0        4           1           2   \n",
       "2012-12-28       1   1    12        0        5           1           2   \n",
       "2012-12-29       1   1    12        0        6           0           2   \n",
       "2012-12-30       1   1    12        0        0           0           1   \n",
       "2012-12-31       1   1    12        0        1           1           2   \n",
       "\n",
       "                temp       hum  windspeed   cnt     bteday  \n",
       "dteday                                                      \n",
       "2011-01-01  0.344167  0.805833   0.160446   985 2011-01-01  \n",
       "2011-01-02  0.363478  0.696087   0.248539   801 2011-01-02  \n",
       "2011-01-03  0.196364  0.437273   0.248309  1349 2011-01-03  \n",
       "2011-01-04  0.200000  0.590435   0.160296  1562 2011-01-04  \n",
       "2011-01-05  0.226957  0.436957   0.186900  1600 2011-01-05  \n",
       "...              ...       ...        ...   ...        ...  \n",
       "2012-12-27  0.254167  0.652917   0.350133  2114 2012-12-27  \n",
       "2012-12-28  0.253333  0.590000   0.155471  3095 2012-12-28  \n",
       "2012-12-29  0.253333  0.752917   0.124383  1341 2012-12-29  \n",
       "2012-12-30  0.255833  0.483333   0.350754  1796 2012-12-30  \n",
       "2012-12-31  0.215833  0.577500   0.154846  2729 2012-12-31  \n",
       "\n",
       "[731 rows x 12 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df = bike_df.drop(labels = ['dteday'], axis = 1)\n",
    "bike_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #3: PERFORM DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 7))\n",
    "bike_df['cnt'].asfreq('W').plot(linewidth = 5)\n",
    "plt.title('Bike Rental Usage Per Week')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bike Rental')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 7))\n",
    "bike_df['cnt'].asfreq('M').plot(linewidth = 5)\n",
    "plt.title('Bike Rental Usage Per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Bike Rental')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bike_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = bike_df[['temp', 'hum', 'windspeed', 'cnt']]\n",
    "X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_numerical);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(X_numerical.corr(), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 [OPTIONAL]:**\n",
    "- **Plot the rental usage per quarter**\n",
    "- **Set the line width to 6 and enable the grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 7))\n",
    "bike_df['cnt'].asfreq('Q').plot(linewidth = 6)\n",
    "plt.title('Bike Rental Usage Per Quarter')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Bike Rental')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #4: CREATE TRAINING AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = bike_df[['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']]\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "X_cat = onehotencoder.fit_transform(X_cat).toarray()\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.DataFrame(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = X_numerical.reset_index()\n",
    "X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_cat, X_numerical], axis = 1)\n",
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.drop('dteday', axis = 1)\n",
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all.iloc[:, :-1].values\n",
    "y = X_all.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #5: TRAIN AN XG-BOOST ALGORITHM IN LOCAL MODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an XGBoost regressor model \n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 1, max_depth = 20, n_estimators = 500)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the score of the trained model using the testing dataset\n",
    "\n",
    "result = model.score(X_test, y_test)\n",
    "print(\"Accuracy : {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test data\n",
    "y_predict = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #3 [OPTIONAL]:**\n",
    "- **Retrain the model with less 'max_depth'**\n",
    "- **Comment on the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #6: PERFORM HYPERPARAMETERS OPTIMIZATION USING GRIDSEARCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = { 'max_depth': [3, 6, 10], \n",
    "                   'learning_rate': [0.01, 0.05, 0.1],\n",
    "                   'n_estimators': [100, 500, 1000],\n",
    "                   'colsample_bytree': [0.3, 0.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we used the \"neg_mean_squared_error\" since GridSearchCV() ranks all the algorithms (estimators) \n",
    "# and specifies which one is the best. We are trying to minimize the error.  \n",
    "xgb_gridsearch = GridSearchCV(estimator = model, \n",
    "                              param_grid = parameters_grid, \n",
    "                              scoring = 'neg_mean_squared_error',  \n",
    "                              cv = 5, \n",
    "                              verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = xgb_gridsearch.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 [OPTIONAL]:**\n",
    "- **Expand on the parameter grid to include an additional hyperparameter \"gamma\"**\n",
    "- **Try any three reasonable values for gamma. How many fits are run this time? Comment on the results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #7: PERFORM HYPERPARAMETERS OPTIMIZATION USING RANDOM SEARCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "\n",
    "# you can choose which booster you'd like to choose: \n",
    "# Two options are available: gbtree, gblinear\n",
    "# gbtree uses tree based models while gblinear uses linear functions\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [100, 500, 700],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'learning_rate': [0.1, 0.5, 1],\n",
    "    'min_child_weight': [1, 2, 3]  \n",
    "            }\n",
    "\n",
    "# grid = {\n",
    "#    'n_estimators': [100, 500, 700],\n",
    "#     'max_depth': [2, 3, 5],\n",
    "#     'learning_rate': [0.1, 0.5, 1],\n",
    "#      'min_child_weight': [1, 2, 3],\n",
    "#     'booster': ['gbtree','gblinear']}\n",
    "\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Set up the random search \n",
    "random_cv = RandomizedSearchCV(estimator = model,\n",
    "                               param_distributions = grid,\n",
    "                               cv = 5, \n",
    "                               n_iter = 50,\n",
    "                               scoring = 'neg_mean_absolute_error',\n",
    "                               verbose = 5, \n",
    "                               return_train_score = True)\n",
    "random_cv.fit(X_train, y_train)\n",
    "\n",
    "random_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = random_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #8: PERFORM HYPERPARAMETERS OPTIMIZATION USING BAYESIAN OPTIMIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's install a library called Scikit-Optimize (Skopt) which is used to perform bayesian optimization \n",
    "# BayesSearchCV class is used in a similar fashion to GridSearchCV\n",
    "# You secify the search space as a distribution instead of discrete values\n",
    "\n",
    "! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"learning_rate\": (0.01, 1.0, \"log-uniform\"),\n",
    "    \"max_depth\": (1, 50),\n",
    "    \"n_estimators\": (5, 500),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bayes_search = BayesSearchCV(model, \n",
    "                               search_space, \n",
    "                               n_iter = 50, \n",
    "                               scoring = 'neg_mean_absolute_error', \n",
    "                               cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgb_bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = xgb_bayes_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CAPSTONE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the used car prices dataset included in the course package, perform the following:\n",
    "1. Load the â€œused_car_price.csvâ€ dataset \n",
    "3. Split the data into 75% for training and 25% for testing \n",
    "4. Train an XG-Boost model in Scikit-Learn\n",
    "5. Assess trained XG-Boost model performance using RMSE and R2 \n",
    "6. Perform hyperparameters optimization using GridSearch, choose any reasonable values for max_depth, learning_rate, n_estimators, and colsample_bytree. Use 5 cross validation folds.  \n",
    "7. Perform hyperparameters optimization using RandomSearch, choose any reasonable values for max_depth, learning_rate, n_estimators, and colsample_bytree. Use 5 cross validation folds and 100 iterations.  \n",
    "8. Perform hyperparameters optimization using Bayesian optimization, choose any reasonable values for max_depth, learning_rate, n_estimators. Use 5 cross validation folds and 100 iterations.  \n",
    "9. Compare the 3 optimization strategies using RMSE and R2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CAPSTONE PROJECT SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file \n",
    "car_df = pd.read_csv(\"used_car_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Origin</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>MSRP</th>\n",
       "      <th>EngineSize</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>MPG_City</th>\n",
       "      <th>MPG_Highway</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>MDX</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Asia</td>\n",
       "      <td>All</td>\n",
       "      <td>36945</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>4451</td>\n",
       "      <td>106</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>RSX Type S 2dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>23820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>2778</td>\n",
       "      <td>101</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acura</td>\n",
       "      <td>TSX 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>26990</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>3230</td>\n",
       "      <td>105</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acura</td>\n",
       "      <td>TL 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>33195</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6</td>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>3575</td>\n",
       "      <td>108</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acura</td>\n",
       "      <td>3.5 RL 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>43755</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>3880</td>\n",
       "      <td>115</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acura</td>\n",
       "      <td>3.5 RL w/Navigation 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>46100</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>3893</td>\n",
       "      <td>115</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Make                    Model   Type Origin DriveTrain   MSRP  EngineSize  \\\n",
       "0  Acura                      MDX    SUV   Asia        All  36945         3.5   \n",
       "1  Acura           RSX Type S 2dr  Sedan   Asia      Front  23820         2.0   \n",
       "2  Acura                  TSX 4dr  Sedan   Asia      Front  26990         2.4   \n",
       "3  Acura                   TL 4dr  Sedan   Asia      Front  33195         3.2   \n",
       "4  Acura               3.5 RL 4dr  Sedan   Asia      Front  43755         3.5   \n",
       "5  Acura  3.5 RL w/Navigation 4dr  Sedan   Asia      Front  46100         3.5   \n",
       "\n",
       "   Cylinders  Horsepower  MPG_City  MPG_Highway  Weight  Wheelbase  Length  \n",
       "0          6         265        17           23    4451        106     189  \n",
       "1          4         200        24           31    2778        101     172  \n",
       "2          4         200        22           29    3230        105     183  \n",
       "3          6         270        20           28    3575        108     186  \n",
       "4          6         225        18           24    3880        115     197  \n",
       "5          6         225        18           24    3893        115     197  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the top 6 instances\n",
    "car_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform One-Hot Encoding for \"Make\", \"Model\", \"Type\", \"Origin\", and \"DriveTrain\"\n",
    "car_df = pd.get_dummies(car_df, columns=[\"Make\", \"Model\", \"Type\", \"Origin\", \"DriveTrain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding input features to X and output (MSRP) to y\n",
    "X = car_df.drop(\"MSRP\", axis = 1)\n",
    "y = car_df[\"MSRP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 483)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 483)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XG-BOOST WITHOUT OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRMSE = 7983.068 \n",
      "R2 = 0.8080216541894797\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 1, max_depth = 3, n_estimators = 500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the score of the trained model using the testing dataset\n",
    "\n",
    "result = model.score(X_test, y_test)\n",
    "# make predictions on the test data\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. XG-BOOST WITH GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, score=-189228899.783, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, score=-64335681.403, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, score=-44818612.165, total=   0.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, score=-39559608.291, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, score=-27286467.264, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, score=-170439813.366, total=   3.1s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, score=-61029622.303, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, score=-45214645.806, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, score=-36565261.608, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, score=-21414070.373, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100, score=-188904297.709, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100, score=-55507988.248, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100, score=-41794674.218, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100, score=-51618167.839, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100, score=-32875202.783, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500, score=-187432382.382, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500, score=-54959405.952, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500, score=-41850251.271, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500, score=-51868493.138, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500, score=-32300028.098, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100, score=-187090542.022, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100, score=-56966370.547, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100, score=-44614627.223, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100, score=-50766533.406, total=   0.9s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100, score=-34470039.919, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500, score=-185421576.377, total=   4.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500, score=-56615106.381, total=   4.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500, score=-44943731.241, total=   4.1s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500, score=-51027748.430, total=   4.1s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500, score=-34305384.839, total=   4.1s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100, score=-212166615.584, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100, score=-66457160.704, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100, score=-87230547.612, total=   0.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100, score=-58794435.991, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100, score=-39507679.561, total=   0.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500, score=-208879465.681, total=   2.5s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500, score=-63689759.763, total=   3.1s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500, score=-87367606.790, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500, score=-58448890.400, total=   2.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500, score=-37485698.204, total=   2.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100, score=-236270110.353, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100, score=-73879788.340, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100, score=-56709520.046, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100, score=-98819566.700, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100, score=-46666174.255, total=   0.7s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500, score=-236269160.402, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500, score=-73852922.518, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500, score=-56709166.384, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500, score=-98839006.102, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500, score=-46591831.588, total=   3.2s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100, score=-238653253.295, total=   0.9s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100, score=-67975936.248, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100, score=-62030327.570, total=   0.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100, score=-101146472.873, total=   1.0s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100, score=-53389503.605, total=   0.9s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500, score=-238653260.654, total=   3.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500, score=-67975859.499, total=   3.9s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500, score=-62030629.979, total=   3.8s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500, score=-101146461.399, total=   3.6s\n",
      "[CV] colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500, score=-53389551.667, total=   3.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, score=-176834320.600, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, score=-73878383.956, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, score=-53433045.807, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, score=-45529021.593, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, score=-34205674.269, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, score=-156899767.788, total=   2.8s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, score=-65939874.210, total=   3.0s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, score=-51215429.707, total=   3.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, score=-44758998.848, total=   2.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, score=-27410889.851, total=   3.0s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, score=-155915531.152, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, score=-69452412.994, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, score=-51013797.825, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, score=-63064992.689, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100, score=-47173339.418, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500, score=-154909105.667, total=   4.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500, score=-68995279.686, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500, score=-50524239.443, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500, score=-63143024.606, total=   4.5s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500, score=-46526342.498, total=   4.5s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100, score=-152862502.182, total=   1.1s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100, score=-76037722.944, total=   1.2s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100, score=-53079237.500, total=   1.2s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100, score=-63466927.745, total=   1.2s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100, score=-46020939.204, total=   1.2s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, score=-151504829.553, total=   6.1s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, score=-75929544.898, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, score=-53179637.134, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, score=-63520667.662, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500, score=-45963507.713, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100, score=-155945986.596, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100, score=-71705243.171, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100, score=-81783357.924, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100, score=-52298924.259, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100, score=-47044381.687, total=   0.6s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500, score=-152303101.501, total=   2.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500, score=-70706177.032, total=   3.0s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500, score=-81343583.581, total=   2.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500, score=-51683826.142, total=   2.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500, score=-45145316.134, total=   3.0s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, score=-165305962.146, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, score=-94391608.857, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, score=-73028004.154, total=   1.0s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, score=-65288420.324, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, score=-76260168.102, total=   0.9s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500, score=-165334424.972, total=   4.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500, score=-94393594.788, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500, score=-73011200.099, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500, score=-65287886.065, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500, score=-76183541.041, total=   4.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100, score=-176334411.304, total=   1.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100, score=-90305418.672, total=   1.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100, score=-67900355.489, total=   1.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100, score=-73714281.019, total=   1.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100, score=-81128031.667, total=   1.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500, score=-176334414.381, total=   6.2s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500, score=-90305392.999, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500, score=-67900351.323, total=   6.3s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500, score=-73714343.611, total=   6.4s\n",
      "[CV] colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500 \n",
      "[CV]  colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500, score=-81128003.600, total=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5090.417 \n",
      "R2 = 0.9219416758954831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_grid = { 'max_depth': [3, 10, 20], \n",
    "                   'learning_rate': [0.1, 0.5],\n",
    "                   'n_estimators': [100, 500],\n",
    "                   'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Note that we used the \"neg_mean_squared_error\" since GridSearchCV() ranks all the algorithms (estimators) \n",
    "# and specifies which one is the best. We are trying to minimize the error.  \n",
    "xgb_gridsearch = GridSearchCV(estimator = model, \n",
    "                              param_grid = parameters_grid, \n",
    "                              scoring = 'neg_mean_squared_error',  \n",
    "                              cv = 5, \n",
    "                              verbose = 5)\n",
    "\n",
    "xgb_gridsearch.fit(X_train, y_train)\n",
    "y_predict = xgb_gridsearch.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. XG-BOOST WITH RANDOMSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-2617.655, test=-5414.073), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-2399.515, test=-4701.138), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-2512.191, test=-4587.913), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-2549.226, test=-4588.942), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-2699.915, test=-3855.046), total=   0.5s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-1152.486, test=-5142.196), total=   2.5s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-1077.416, test=-4468.399), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-1065.646, test=-4345.897), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-1120.250, test=-4393.017), total=   2.5s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.3, score=(train=-1215.227, test=-3385.168), total=   2.6s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-267.962, test=-5377.139), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-265.050, test=-4612.487), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-294.723, test=-4513.926), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-254.380, test=-4830.209), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-256.512, test=-3704.773), total=   0.7s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-18.244, test=-5359.408), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-14.369, test=-4599.432), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-23.069, test=-4487.255), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-15.778, test=-4848.406), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.3, score=(train=-18.837, test=-3654.502), total=   3.3s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-62.382, test=-5412.148), total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-60.433, test=-4722.081), total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-63.158, test=-4416.888), total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-67.483, test=-4850.516), total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-63.775, test=-3978.956), total=   0.8s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-0.013, test=-5396.553), total=   4.1s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-0.013, test=-4718.338), total=   4.2s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-0.014, test=-4421.238), total=   4.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-0.015, test=-4858.742), total=   4.6s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.3, score=(train=-0.014, test=-3968.106), total=   4.3s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-937.646, test=-6134.694), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-1011.146, test=-5115.361), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-957.706, test=-5435.394), total=   0.5s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-964.301, test=-5132.444), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-1118.756, test=-4116.235), total=   0.5s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-86.229, test=-5994.018), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-75.188, test=-4968.935), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-92.477, test=-5397.737), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-81.599, test=-5078.884), total=   2.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.3, score=(train=-82.983, test=-3998.341), total=   2.6s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-15.185, test=-6982.305), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-12.921, test=-5517.467), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-16.353, test=-5215.885), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-26.857, test=-5890.047), total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-34.713, test=-4493.062), total=   0.7s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-6981.603), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-5517.997), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-5216.980), total=   3.7s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-5891.548), total=   3.2s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.002, test=-4488.125), total=   3.2s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.003, test=-7093.610), total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.002, test=-5733.845), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.003, test=-5479.892), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.002, test=-6026.737), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-4859.866), total=   0.8s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.000, test=-7093.610), total=   3.7s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-5733.845), total=   3.8s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-5479.902), total=   3.9s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.000, test=-6026.738), total=   3.8s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.3, score=(train=-0.001, test=-4859.864), total=   3.9s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-2287.917, test=-5418.358), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-2403.652, test=-5051.088), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-2327.041, test=-4542.609), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-2503.233, test=-4493.877), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-2685.628, test=-4081.471), total=   0.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-1001.123, test=-4914.704), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-995.532, test=-4659.797), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-1023.536, test=-4265.209), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-1067.241, test=-4372.731), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.1, colsample_bytree=0.7, score=(train=-1207.968, test=-3627.070), total=   2.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-246.191, test=-5523.410), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-226.455, test=-4747.673), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-258.592, test=-4536.326), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-178.016, test=-4743.361), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-253.217, test=-4326.008), total=   0.9s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-11.444, test=-5513.972), total=   4.3s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-12.478, test=-4733.586), total=   4.4s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-15.299, test=-4496.661), total=   4.4s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-7.758, test=-4739.206), total=   4.4s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.1, colsample_bytree=0.7, score=(train=-18.973, test=-4278.330), total=   4.4s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-31.301, test=-5649.974), total=   1.2s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-31.556, test=-5020.448), total=   1.2s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-31.664, test=-4599.465), total=   1.2s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-30.805, test=-4905.406), total=   1.2s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-34.350, test=-4286.762), total=   1.2s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-0.014, test=-5642.057), total=   6.4s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-0.012, test=-5018.807), total=   6.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-0.015, test=-4599.665), total=   6.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-0.013, test=-4908.550), total=   6.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.1, colsample_bytree=0.7, score=(train=-0.014, test=-4283.500), total=   6.3s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-956.569, test=-5679.972), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-969.115, test=-4841.151), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-902.545, test=-5404.154), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-928.443, test=-4800.847), total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-1009.034, test=-4263.487), total=   0.6s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-61.902, test=-5648.618), total=   2.8s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-74.933, test=-4731.583), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-70.613, test=-5314.508), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-89.012, test=-4770.083), total=   2.9s\n",
      "[CV] n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=3, learning_rate=0.5, colsample_bytree=0.7, score=(train=-75.901, test=-4140.499), total=   2.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-10.949, test=-6209.419), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-9.017, test=-6010.740), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-14.254, test=-5684.882), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-8.005, test=-5170.984), total=   0.9s\n",
      "[CV] n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-17.247, test=-5380.456), total=   0.9s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-6209.053), total=   4.3s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.003, test=-6011.299), total=   4.5s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5683.529), total=   5.0s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5170.726), total=   4.4s\n",
      "[CV] n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=10, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.003, test=-5377.350), total=   4.4s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-6460.725), total=   1.3s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5924.941), total=   1.3s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5592.905), total=   1.3s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5405.056), total=   1.3s\n",
      "[CV] n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=100, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.002, test=-5500.367), total=   1.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-6460.725), total=   6.2s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-5924.942), total=   6.4s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-5592.904), total=   6.2s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-5405.059), total=   6.3s\n",
      "[CV] n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7 \n",
      "[CV]  n_estimators=500, max_depth=20, learning_rate=0.5, colsample_bytree=0.7, score=(train=-0.001, test=-5500.365), total=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5090.417 \n",
      "R2 = 0.9219416758954831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "\n",
    "# you can choose which booster you'd like to choose: \n",
    "# Two options are available: gbtree, gblinear\n",
    "# gbtree uses tree based models while gblinear uses linear functions\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth': [3, 10, 20],\n",
    "    'learning_rate': [0.1, 0.5], \n",
    "    'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Set up the random search \n",
    "random_cv = RandomizedSearchCV(estimator = model,\n",
    "                               param_distributions = grid,\n",
    "                               cv = 5, \n",
    "                               n_iter = 100,\n",
    "                               scoring = 'neg_mean_absolute_error',\n",
    "                               verbose = 5, \n",
    "                               return_train_score = True)\n",
    "random_cv.fit(X_train, y_train)\n",
    "\n",
    "random_cv.best_estimator_\n",
    "y_predict = random_cv.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XG-BOOST WITH BAYESIAN OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize) (1.21.6)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRMSE = 5172.579 \n",
      "R2 = 0.9194015306306565\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_space = {\n",
    "        \"max_depth\": (4, 20, 'log-uniform'),\n",
    "        \"n_estimators\": (2, 100, 'log-uniform'),\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform')}            \n",
    "\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_bayes_search = BayesSearchCV(model, \n",
    "                                    search_space, \n",
    "                                    n_iter = 100, \n",
    "                                    scoring = 'neg_mean_absolute_error', \n",
    "                                    cv = 5)\n",
    "\n",
    "xgb_bayes_search.fit(X_train, y_train) \n",
    "\n",
    "y_predict = xgb_bayes_search.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICE OPPORTUNITIES SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 SOLUTION:**\n",
    "- **What is the average, minimum and maximum registered bike rental usage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 SOLUTION:**\n",
    "- **Plot the rental usage per quarter**\n",
    "- **Set the line width to 6 and enable the grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df['cnt'].asfreq('Q').plot(linewidth = 6)\n",
    "plt.title('Bike Usage Per Quarter')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Bike Rental')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #3 SOLUTION:**\n",
    "- **Retrain the model with less 'max_depth'**\n",
    "- **Comment on the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an XGBoost regressor model \n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 1, max_depth = 3, n_estimators = 500)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 SOLUTION:**\n",
    "- **Expand on the parameter grid to include an additional hyperparameter \"gamma\"**\n",
    "- **Try any three reasonable values for gamma. How many fits are run this time? Comment on the results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_grid = { 'max_depth': [3, 6, 10], \n",
    "                    'learning_rate': [0.01, 0.05, 0.1],\n",
    "                    'n_estimators': [100, 500, 1000],\n",
    "                    'colsample_bytree': [0.3, 0.7],\n",
    "                    'gamma': [1, 0.1, 0.01]}\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "# Note that we used the \"neg_mean_squared_error\" since GridSearchCV() ranks all the algorithms (estimators) \n",
    "# and specifies which one is the best. We are trying to minimize the error.  \n",
    "xgb_gridsearch = GridSearchCV(estimator = model, \n",
    "                              param_grid = parameters_grid, \n",
    "                              scoring = 'neg_mean_squared_error',  \n",
    "                              cv = 5, \n",
    "                              verbose = 5)\n",
    "xgb_gridsearch\n",
    "xgb_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = xgb_gridsearch.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "collapsed_sections": [],
   "name": "Retail Sales Forecast.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
